{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73730f09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------\n",
    "print(\"ðŸ“‚ Loading dataset...\")\n",
    "df = pd.read_csv(\"EdgeIIoT-dataset.csv\")\n",
    "\n",
    "# Drop irrelevant identifier/payload columns\n",
    "drop_cols = [\n",
    "    \"ip.src_host\", \"ip.dst_host\", \"arp.dst.proto_ipv4\", \"arp.src.proto_ipv4\",\n",
    "    \"http.file_data\", \"http.request.uri.query\", \"http.referer\",\n",
    "    \"http.request.full_uri\", \"tcp.options\", \"tcp.payload\",\n",
    "    \"dns.qry.name\", \"dns.qry.name.len\", \"mqtt.msg\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Separate labels AND keep attack types\n",
    "# -----------------------------\n",
    "labels = df[[\"Attack_label\", \"Attack_type\"]].copy()\n",
    "attack_types_original = df[\"Attack_type\"].values  # *** NEW: Keep original attack types ***\n",
    "df = df.drop(columns=[\"Attack_label\", \"Attack_type\"], errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Encode categorical columns\n",
    "# -----------------------------\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.drop(\"frame.time\", errors=\"ignore\")\n",
    "for col in categorical_cols:\n",
    "    n_unique = df[col].nunique()\n",
    "    if n_unique < 50:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    else:\n",
    "        freq = df[col].value_counts()\n",
    "        df[col] = df[col].map(freq)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Scale numerical features\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "features = df.drop(columns=[\"frame.time\"], errors=\"ignore\")\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "X[\"Attack_label\"] = labels[\"Attack_label\"].values\n",
    "X[\"Attack_type\"] = labels[\"Attack_type\"].values\n",
    "if \"frame.time\" in df.columns:\n",
    "    X[\"frame.time\"] = df[\"frame.time\"].values\n",
    "\n",
    "# Sort chronologically (important for sequential structure)\n",
    "if \"frame.time\" in X.columns:\n",
    "    X = X.sort_values(\"frame.time\").reset_index(drop=True)\n",
    "    # *** IMPORTANT: Also reorder attack_types_original to match ***\n",
    "    attack_types_original = X[\"Attack_type\"].values\n",
    "\n",
    "print(f\"âœ… Preprocessed features: {X.shape[1]} columns\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Sliding window (stride = 4) WITH ATTACK TYPE TRACKING\n",
    "# -----------------------------\n",
    "def sliding_window_with_attack_types(data, binary_labels, attack_types, \n",
    "                                      window=32, step=4, anomaly_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Create sliding windows with robust anomaly labeling AND track attack types.\n",
    "    \n",
    "    Args:\n",
    "        data: Feature data\n",
    "        binary_labels: Binary labels (0=normal, 1=anomaly)\n",
    "        attack_types: Attack type strings for each packet\n",
    "        window: Window size (number of time steps)\n",
    "        step: Stride between windows\n",
    "        anomaly_threshold: Minimum proportion of anomalies needed (default: 0.4 = 40%)\n",
    "    \n",
    "    Returns:\n",
    "        X_seq: Array of windows (n_windows, window, n_features)\n",
    "        y_seq: Binary labels for windows (n_windows,)\n",
    "        attack_type_seq: Most prevalent attack type per window (n_windows,)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq, attack_type_seq = [], [], []\n",
    "    \n",
    "    for start in range(0, len(data) - window, step):\n",
    "        end = start + window\n",
    "        X_seq.append(data.iloc[start:end].values)\n",
    "        \n",
    "        # Calculate proportion of anomalies in this window\n",
    "        window_labels = binary_labels.iloc[start:end]\n",
    "        anomaly_ratio = window_labels.sum() / len(window_labels)\n",
    "        \n",
    "        # Label as anomalous only if >= threshold\n",
    "        y_seq.append(int(anomaly_ratio >= anomaly_threshold))\n",
    "        \n",
    "        # *** NEW: Determine most prevalent attack type in window ***\n",
    "        window_attack_types = attack_types[start:end]\n",
    "        most_common_attack = Counter(window_attack_types).most_common(1)[0][0]\n",
    "        attack_type_seq.append(most_common_attack)\n",
    "    \n",
    "    return (np.array(X_seq, dtype=np.float32), \n",
    "            np.array(y_seq, dtype=np.int8),\n",
    "            np.array(attack_type_seq))\n",
    "\n",
    "print(\"ðŸªŸ Generating sliding windows (window=32, step=4, â‰¥40% anomalies required)...\")\n",
    "X_seq, y_seq, attack_type_seq = sliding_window_with_attack_types(\n",
    "    X.drop(columns=[\"Attack_label\", \"Attack_type\", \"frame.time\"], errors=\"ignore\"),\n",
    "    X[\"Attack_label\"],\n",
    "    attack_types_original,  # *** NEW: Pass attack types ***\n",
    "    window=32,\n",
    "    step=4,\n",
    "    anomaly_threshold=0.4  # 40% threshold\n",
    ")\n",
    "\n",
    "print(f\"âœ… Total windows: {len(X_seq):,}\")\n",
    "print(f\"âœ… Window shape: {X_seq.shape[1:]} (time steps Ã— features)\")\n",
    "print(f\"âœ… Attack types tracked: {len(np.unique(attack_type_seq))} unique types\")\n",
    "\n",
    "# Show attack type distribution\n",
    "print(\"\\nðŸ“Š Attack type distribution in all windows:\")\n",
    "attack_counts = Counter(attack_type_seq)\n",
    "for attack_type, count in attack_counts.most_common(10):  # Top 10\n",
    "    pct = count / len(attack_type_seq) * 100\n",
    "    print(f\"  {attack_type:30s}: {count:8,} ({pct:5.2f}%)\")\n",
    "if len(attack_counts) > 10:\n",
    "    print(f\"  ... and {len(attack_counts) - 10} more attack types\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Chronological Train/Test Split (80/20, time-based)\n",
    "# -----------------------------\n",
    "split_idx = int(0.8 * len(X_seq))  # First 80% train, last 20% test\n",
    "X_train_seq = X_seq[:split_idx]\n",
    "y_train_seq = y_seq[:split_idx]\n",
    "attack_types_train = attack_type_seq[:split_idx]  # *** NEW: Split attack types ***\n",
    "\n",
    "X_test = X_seq[split_idx:]\n",
    "y_test = y_seq[split_idx:]\n",
    "attack_types_test = attack_type_seq[split_idx:]  # *** NEW: Split attack types ***\n",
    "\n",
    "# From train: Create ConvAE + PPO sets\n",
    "anomaly_indices = np.where(y_train_seq == 1)[0]\n",
    "num_labeled = int(0.05 * len(anomaly_indices))  # 5% labeled anomalies\n",
    "\n",
    "labeled_anom_idx = np.random.choice(anomaly_indices, num_labeled, replace=False)\n",
    "X_labeled = X_train_seq[labeled_anom_idx]\n",
    "y_labeled = y_train_seq[labeled_anom_idx]\n",
    "\n",
    "unlabeled_idx = np.setdiff1d(np.arange(len(X_train_seq)), labeled_anom_idx)\n",
    "X_unlabeled = X_train_seq[unlabeled_idx]\n",
    "y_unlabeled = y_train_seq[unlabeled_idx]  # For sanity checks only; hide in training\n",
    "\n",
    "# ConvAE trained only on normal sequences from train\n",
    "normal_indices = np.where(y_train_seq == 0)[0]\n",
    "X_ae = X_train_seq[normal_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save outputs WITH INDICES AND ATTACK TYPES\n",
    "# -----------------------------\n",
    "np.save(\"X_ae.npy\", X_ae)\n",
    "np.save(\"X_unlabeled.npy\", X_unlabeled)\n",
    "np.save(\"y_unlabeled.npy\", y_unlabeled)\n",
    "np.save(\"X_labeled.npy\", X_labeled)\n",
    "np.save(\"y_labeled.npy\", y_labeled)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "np.save(\"y_train_seq.npy\", y_train_seq)\n",
    "\n",
    "# *** NEW: Save attack types ***\n",
    "np.save(\"attack_types_test.npy\", attack_types_test)\n",
    "np.save(\"attack_types_train.npy\", attack_types_train)\n",
    "\n",
    "# Save indices for reconstruction\n",
    "np.save(\"labeled_indices.npy\", labeled_anom_idx)\n",
    "np.save(\"unlabeled_indices.npy\", unlabeled_idx)\n",
    "np.save(\"train_split_size.npy\", np.array([len(X_train_seq)]))\n",
    "\n",
    "print(\"\\nðŸ’¾ Saved arrays:\")\n",
    "print(f\"  X_ae         : {X_ae.shape} ({X_ae.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_unlabeled  : {X_unlabeled.shape} ({X_unlabeled.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_labeled    : {X_labeled.shape} ({X_labeled.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_test       : {X_test.shape} ({X_test.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"\\n  attack_types_test  : {attack_types_test.shape}\")\n",
    "print(f\"  attack_types_train : {attack_types_train.shape}\")\n",
    "print(f\"  labeled_indices    : {labeled_anom_idx.shape}\")\n",
    "print(f\"  unlabeled_indices  : {unlabeled_idx.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Dataset Statistics\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training split statistics\n",
    "train_normal = np.sum(y_train_seq == 0)\n",
    "train_anomaly = np.sum(y_train_seq == 1)\n",
    "train_total = len(y_train_seq)\n",
    "print(f\"\\nðŸ”¹ TRAINING SPLIT (First 80% chronologically):\")\n",
    "print(f\"  Total windows    : {train_total:,}\")\n",
    "print(f\"  Normal windows   : {train_normal:,} ({train_normal/train_total*100:.2f}%)\")\n",
    "print(f\"  Anomaly windows  : {train_anomaly:,} ({train_anomaly/train_total*100:.2f}%)\")\n",
    "\n",
    "# Test split statistics\n",
    "test_normal = np.sum(y_test == 0)\n",
    "test_anomaly = np.sum(y_test == 1)\n",
    "test_total = len(y_test)\n",
    "print(f\"\\nðŸ”¹ TEST SPLIT (Last 20% chronologically):\")\n",
    "print(f\"  Total windows    : {test_total:,}\")\n",
    "print(f\"  Normal windows   : {test_normal:,} ({test_normal/test_total*100:.2f}%)\")\n",
    "print(f\"  Anomaly windows  : {test_anomaly:,} ({test_anomaly/test_total*100:.2f}%)\")\n",
    "\n",
    "# *** NEW: Attack type statistics for test set ***\n",
    "print(f\"\\nðŸ”¹ TEST SET ATTACK TYPES:\")\n",
    "test_attack_counts = Counter(attack_types_test)\n",
    "for attack_type, count in test_attack_counts.most_common():\n",
    "    pct = count / len(attack_types_test) * 100\n",
    "    print(f\"  {attack_type:30s}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nðŸ”¹ OVERALL:\")\n",
    "print(f\"  Total windows    : {train_total + test_total:,}\")\n",
    "print(f\"  Normal windows   : {train_normal + test_normal:,}\")\n",
    "print(f\"  Anomaly windows  : {train_anomaly + test_anomaly:,}\")\n",
    "print(f\"  Unique attacks   : {len(np.unique(attack_type_seq))}\")\n",
    "\n",
    "# Labeled data info\n",
    "print(f\"\\nðŸ”¹ LABELED ANOMALIES (for PPO training):\")\n",
    "print(f\"  Labeled anomalies: {len(X_labeled):,} ({len(X_labeled)/train_anomaly*100:.2f}% of train anomalies)\")\n",
    "print(f\"  Unlabeled data   : {len(X_unlabeled):,}\")\n",
    "print(f\"  ConvAE data      : {len(X_ae):,} (normal sequences only)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ… Preprocessing complete! Ready for ConvAE and PPO training.\")\n",
    "print(f\"âœ… Index files saved for reconstruction: labeled_indices.npy, unlabeled_indices.npy\")\n",
    "print(f\"âœ… Attack type information saved: attack_types_test.npy, attack_types_train.npy\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
