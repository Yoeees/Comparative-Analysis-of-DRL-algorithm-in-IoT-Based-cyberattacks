{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd52d6-6b12-446e-9caf-fbbc091f7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Load pretrained ConvAE (frozen) and AE stats\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ae_model = ConvAE(feat_dim=X_unlabeled.shape[2], seq_len=X_unlabeled.shape[1], latent_dim=128)\n",
    "ae_model.load_state_dict(torch.load(\"convAE_best.pth\", map_location=device))\n",
    "ae_model.to(device)\n",
    "ae_model.eval()\n",
    "for p in ae_model.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f\"‚úÖ Loaded ConvAE on {device} (frozen for RecurrentPPO).\")\n",
    "\n",
    "stats = np.load(\"convAE_stats.npz\")\n",
    "ae_mean, ae_std = stats[\"mean_err\"], stats[\"std_err\"]\n",
    "print(f\"‚úÖ AE normalization loaded: mean={ae_mean:.6f}, std={ae_std:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Reconstruct chronological order\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ RECONSTRUCTING CHRONOLOGICAL ORDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load labeled and unlabeled data\n",
    "X_labeled = np.load(\"X_labeled.npy\")\n",
    "y_labeled = np.load(\"y_labeled.npy\")\n",
    "X_unlabeled = np.load(\"X_unlabeled.npy\")\n",
    "y_unlabeled = np.load(\"y_unlabeled.npy\")\n",
    "\n",
    "# Load indices\n",
    "labeled_indices = np.load(\"labeled_indices.npy\")\n",
    "unlabeled_indices = np.load(\"unlabeled_indices.npy\")\n",
    "train_split_size = np.load(\"train_split_size.npy\")[0]\n",
    "\n",
    "print(f\"üìä Data loaded:\")\n",
    "print(f\"   Labeled samples: {len(X_labeled):,}\")\n",
    "print(f\"   Unlabeled samples: {len(X_unlabeled):,}\")\n",
    "print(f\"   Original training size: {train_split_size:,}\")\n",
    "\n",
    "# Reconstruct X and y in chronological order\n",
    "X_train_reconstructed = np.zeros((train_split_size, *X_labeled.shape[1:]), dtype=X_labeled.dtype)\n",
    "y_train_reconstructed = np.zeros(train_split_size, dtype=y_labeled.dtype)\n",
    "\n",
    "# Place data back at original positions\n",
    "X_train_reconstructed[labeled_indices] = X_labeled\n",
    "y_train_reconstructed[labeled_indices] = y_labeled\n",
    "X_train_reconstructed[unlabeled_indices] = X_unlabeled\n",
    "y_train_reconstructed[unlabeled_indices] = y_unlabeled\n",
    "\n",
    "# Create supervision mask (1 = labeled/supervised, 0 = unlabeled/unsupervised)\n",
    "supervision_mask = np.zeros(train_split_size, dtype=np.int8)\n",
    "supervision_mask[labeled_indices] = 1  # These positions have supervision\n",
    "\n",
    "print(f\"\\n‚úÖ Reconstructed training data:\")\n",
    "print(f\"   Shape: {X_train_reconstructed.shape}\")\n",
    "print(f\"   Supervised positions: {np.sum(supervision_mask):,} ({np.sum(supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "print(f\"   Unsupervised positions: {np.sum(1-supervision_mask):,} ({np.sum(1-supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "\n",
    "# Verify reconstruction\n",
    "y_train_original = np.load(\"y_train_seq.npy\")\n",
    "if np.array_equal(y_train_reconstructed, y_train_original):\n",
    "    print(\"‚úÖ VERIFICATION PASSED: Reconstruction matches original!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Reconstruction mismatch detected!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PPO Environment (Chronological Sequential)\n",
    "# ============================================================================\n",
    "\n",
    "class PPOAEEnvChronological(gym.Env):\n",
    "    \"\"\"\n",
    "    Sequential environment that processes windows in chronological order.\n",
    "    Uses supervision_mask to determine which positions have labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train, supervision_mask, ae_model,\n",
    "                 embeddings, lambda_int=1.0, max_steps=200):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.supervision_mask = supervision_mask  # 1=supervised, 0=unsupervised\n",
    "        self.ae_model = ae_model\n",
    "        self.device = next(ae_model.parameters()).device\n",
    "        self.lambda_int = lambda_int\n",
    "        self.max_steps = max_steps\n",
    "        self.steps = 0\n",
    "        self.idx = 0\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        emb_dim = self.embeddings.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(emb_dim + 1,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = normal, 1 = anomaly\n",
    "\n",
    "        # Statistics\n",
    "        n_supervised = np.sum(supervision_mask)\n",
    "        n_unsupervised = len(supervision_mask) - n_supervised\n",
    "        print(f\"\\nüîπ Environment initialized:\")\n",
    "        print(f\"   Total windows: {len(X_train):,}\")\n",
    "        print(f\"   Supervised: {n_supervised:,} ({n_supervised/len(X_train)*100:.2f}%)\")\n",
    "        print(f\"   Unsupervised: {n_unsupervised:,} ({n_unsupervised/len(X_train)*100:.2f}%)\")\n",
    "\n",
    "    def _ae_error(self, x):\n",
    "        \"\"\"Compute normalized reconstruction error.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            recon = self.ae_model(x)\n",
    "            loss = F.mse_loss(recon, x, reduction=\"mean\").item()\n",
    "        norm = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "        return max(0, norm)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Reset to start of sequence (or random position 10% of time).\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        \n",
    "        # Start from beginning or random position\n",
    "        if np.random.rand() < 0.1:  # 10% random start for variety\n",
    "            self.idx = np.random.randint(0, len(self.X_train))\n",
    "        else:\n",
    "            self.idx = 0\n",
    "        \n",
    "        emb = self.embeddings[self.idx]\n",
    "        err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([emb, err]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take action on current window, move to next chronologically.\"\"\"\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Current window\n",
    "        x = self.X_train[self.idx]\n",
    "        true_label = self.y_train[self.idx]\n",
    "        is_supervised = self.supervision_mask[self.idx]\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        err = self._ae_error(x)\n",
    "        \n",
    "        # ========== REWARD CALCULATION ==========\n",
    "        \n",
    "        # External reward (only for supervised positions)\n",
    "        if is_supervised == 1:\n",
    "            # We have ground truth label\n",
    "            external_reward = 1.0 if action == true_label else -0.5\n",
    "        else:\n",
    "            # No supervision - no external reward\n",
    "            external_reward = 0.0\n",
    "        \n",
    "        # Intrinsic reward (based on reconstruction error)\n",
    "        # Encourage anomaly prediction when error is high\n",
    "        if action == 1:  # Predicted anomaly\n",
    "            intrinsic_reward = self.lambda_int * err\n",
    "            # Penalize weak false positives\n",
    "            if err < 0.05:\n",
    "                intrinsic_reward -= 0.5\n",
    "        else:  # Predicted normal\n",
    "            intrinsic_reward = 0.0\n",
    "        \n",
    "        # Total reward\n",
    "        reward = external_reward + intrinsic_reward\n",
    "        reward = np.clip(reward, -5, 5)\n",
    "        \n",
    "        # ========== MOVE TO NEXT WINDOW (CHRONOLOGICALLY) ==========\n",
    "        self.idx = (self.idx + 1) % len(self.X_train)\n",
    "        \n",
    "        # Next observation\n",
    "        next_emb = self.embeddings[self.idx]\n",
    "        next_err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([next_emb, next_err]).astype(np.float32)\n",
    "        \n",
    "        done = self.steps >= self.max_steps\n",
    "        \n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Precompute embeddings\n",
    "# ============================================================================\n",
    "\n",
    "def compute_embeddings(X):\n",
    "    \"\"\"Compute embeddings for all windows.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        tensors = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        embeds = ae_model.encode(tensors).cpu().numpy()\n",
    "    return embeds\n",
    "\n",
    "print(\"üîπ Precomputing embeddings for reconstructed data...\")\n",
    "embeddings_train = compute_embeddings(X_train_reconstructed)\n",
    "print(f\"‚úÖ Embeddings computed: {embeddings_train.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create VecEnv + Recurrent PPO\n",
    "# ============================================================================\n",
    "\n",
    "def make_env(rank):\n",
    "    def _init():\n",
    "        env = PPOAEEnvChronological(\n",
    "            X_train_reconstructed, \n",
    "            y_train_reconstructed, \n",
    "            supervision_mask,\n",
    "            ae_model,\n",
    "            embeddings_train,\n",
    "            lambda_int=0.8, \n",
    "            max_steps=200\n",
    "        )\n",
    "        return Monitor(env, f\"logs/env_{rank}\")\n",
    "    return _init\n",
    "\n",
    "num_envs = 1\n",
    "vec_env = DummyVecEnv([make_env(i) for i in range(num_envs)])\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    lstm_hidden_size=128,\n",
    "    n_lstm_layers=1,\n",
    "    shared_lstm=False,\n",
    "    net_arch=dict(pi=[256, 256], vf=[512, 512, 256])\n",
    ")\n",
    "\n",
    "model = RecurrentPPO(\n",
    "    \"MlpLstmPolicy\",\n",
    "    vec_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    n_steps=128,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.02,\n",
    "    clip_range=0.2,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    tensorboard_log=\"logs_recurrent_ppo_ae_chronological/\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ Starting RecurrentPPO training with chronological data\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Train Recurrent PPO\n",
    "# ============================================================================\n",
    "\n",
    "model.learn(total_timesteps=200_000)\n",
    "model.save(\"recurrent_ppo_ae_chronological\")\n",
    "vec_env.save(\"vec_normalize_recurrent_ppo_chronological.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! Chronological PPO model saved.\")\n",
    "print(\"   Model: recurrent_ppo_ae_chronological.zip\")\n",
    "print(\"   VecNormalize: vec_normalize_recurrent_ppo_chronological.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aee8f6-793b-42dd-938f-30d056c2cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sb3_contrib import QRDQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Load pretrained ConvAE (frozen) and AE stats\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ae_model = ConvAE(feat_dim=X_unlabeled.shape[2], seq_len=X_unlabeled.shape[1], latent_dim=128)\n",
    "ae_model.load_state_dict(torch.load(\"convAE_best.pth\", map_location=device))\n",
    "ae_model.to(device)\n",
    "ae_model.eval()\n",
    "for p in ae_model.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f\"‚úÖ Loaded ConvAE on {device} (frozen for QR-DQN).\")\n",
    "\n",
    "stats = np.load(\"convAE_stats.npz\")\n",
    "ae_mean, ae_std = stats[\"mean_err\"], stats[\"std_err\"]\n",
    "print(f\"‚úÖ AE normalization loaded: mean={ae_mean:.6f}, std={ae_std:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Reconstruct chronological order\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ RECONSTRUCTING CHRONOLOGICAL ORDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load labeled and unlabeled data\n",
    "X_labeled = np.load(\"X_labeled.npy\")\n",
    "y_labeled = np.load(\"y_labeled.npy\")\n",
    "X_unlabeled = np.load(\"X_unlabeled.npy\")\n",
    "y_unlabeled = np.load(\"y_unlabeled.npy\")\n",
    "\n",
    "# Load indices\n",
    "labeled_indices = np.load(\"labeled_indices.npy\")\n",
    "unlabeled_indices = np.load(\"unlabeled_indices.npy\")\n",
    "train_split_size = np.load(\"train_split_size.npy\")[0]\n",
    "\n",
    "print(f\"üìä Data loaded:\")\n",
    "print(f\"   Labeled samples: {len(X_labeled):,}\")\n",
    "print(f\"   Unlabeled samples: {len(X_unlabeled):,}\")\n",
    "print(f\"   Original training size: {train_split_size:,}\")\n",
    "\n",
    "# Reconstruct X and y in chronological order\n",
    "X_train_reconstructed = np.zeros((train_split_size, *X_labeled.shape[1:]), dtype=X_labeled.dtype)\n",
    "y_train_reconstructed = np.zeros(train_split_size, dtype=y_labeled.dtype)\n",
    "\n",
    "# Place data back at original positions\n",
    "X_train_reconstructed[labeled_indices] = X_labeled\n",
    "y_train_reconstructed[labeled_indices] = y_labeled\n",
    "X_train_reconstructed[unlabeled_indices] = X_unlabeled\n",
    "y_train_reconstructed[unlabeled_indices] = y_unlabeled\n",
    "\n",
    "# Create supervision mask (1 = labeled/supervised, 0 = unlabeled/unsupervised)\n",
    "supervision_mask = np.zeros(train_split_size, dtype=np.int8)\n",
    "supervision_mask[labeled_indices] = 1\n",
    "\n",
    "print(f\"\\n‚úÖ Reconstructed training data:\")\n",
    "print(f\"   Shape: {X_train_reconstructed.shape}\")\n",
    "print(f\"   Supervised positions: {np.sum(supervision_mask):,} ({np.sum(supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "print(f\"   Unsupervised positions: {np.sum(1-supervision_mask):,} ({np.sum(1-supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "\n",
    "# Verify reconstruction\n",
    "y_train_original = np.load(\"y_train_seq.npy\")\n",
    "if np.array_equal(y_train_reconstructed, y_train_original):\n",
    "    print(\"‚úÖ VERIFICATION PASSED: Reconstruction matches original!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Reconstruction mismatch detected!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: QR-DQN Environment (Chronological Sequential)\n",
    "# ============================================================================\n",
    "\n",
    "class QRDQNAEEnvChronological(gym.Env):\n",
    "    \"\"\"\n",
    "    Sequential environment that processes windows in chronological order.\n",
    "    Uses supervision_mask to determine which positions have labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train, supervision_mask, ae_model,\n",
    "                 embeddings, lambda_int=1.0, max_steps=200):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.supervision_mask = supervision_mask\n",
    "        self.ae_model = ae_model\n",
    "        self.device = next(ae_model.parameters()).device\n",
    "        self.lambda_int = lambda_int\n",
    "        self.max_steps = max_steps\n",
    "        self.steps = 0\n",
    "        self.idx = 0\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        emb_dim = self.embeddings.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(emb_dim + 1,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = normal, 1 = anomaly\n",
    "\n",
    "        # Statistics\n",
    "        n_supervised = np.sum(supervision_mask)\n",
    "        n_unsupervised = len(supervision_mask) - n_supervised\n",
    "        print(f\"\\nüîπ Environment initialized:\")\n",
    "        print(f\"   Total windows: {len(X_train):,}\")\n",
    "        print(f\"   Supervised: {n_supervised:,} ({n_supervised/len(X_train)*100:.2f}%)\")\n",
    "        print(f\"   Unsupervised: {n_unsupervised:,} ({n_unsupervised/len(X_train)*100:.2f}%)\")\n",
    "\n",
    "    def _ae_error(self, x):\n",
    "        \"\"\"Compute normalized reconstruction error.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            recon = self.ae_model(x)\n",
    "            loss = F.mse_loss(recon, x, reduction=\"mean\").item()\n",
    "        norm = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "        return max(0, norm)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Reset to start of sequence (or random position 10% of time).\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        \n",
    "        # Start from beginning or random position\n",
    "        if np.random.rand() < 0.1:  # 10% random start for variety\n",
    "            self.idx = np.random.randint(0, len(self.X_train))\n",
    "        else:\n",
    "            self.idx = 0\n",
    "        \n",
    "        emb = self.embeddings[self.idx]\n",
    "        err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([emb, err]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take action on current window, move to next chronologically.\"\"\"\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Current window\n",
    "        x = self.X_train[self.idx]\n",
    "        true_label = self.y_train[self.idx]\n",
    "        is_supervised = self.supervision_mask[self.idx]\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        err = self._ae_error(x)\n",
    "        \n",
    "        # ========== REWARD CALCULATION ==========\n",
    "        \n",
    "        # External reward (only for supervised positions)\n",
    "        if is_supervised == 1:\n",
    "            # We have ground truth label\n",
    "            external_reward = 1.0 if action == true_label else -0.5\n",
    "        else:\n",
    "            # No supervision - no external reward\n",
    "            external_reward = 0.0\n",
    "        \n",
    "        # Intrinsic reward (based on reconstruction error)\n",
    "        # Encourage anomaly prediction when error is high\n",
    "        if action == 1:  # Predicted anomaly\n",
    "            intrinsic_reward = self.lambda_int * err\n",
    "            # Penalize weak false positives\n",
    "            if err < 0.05:\n",
    "                intrinsic_reward -= 0.5\n",
    "        else:  # Predicted normal\n",
    "            intrinsic_reward = 0.0\n",
    "        \n",
    "        # Total reward\n",
    "        reward = external_reward + intrinsic_reward\n",
    "        reward = np.clip(reward, -5, 5)\n",
    "        \n",
    "        # ========== MOVE TO NEXT WINDOW (CHRONOLOGICALLY) ==========\n",
    "        self.idx = (self.idx + 1) % len(self.X_train)\n",
    "        \n",
    "        # Next observation\n",
    "        next_emb = self.embeddings[self.idx]\n",
    "        next_err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([next_emb, next_err]).astype(np.float32)\n",
    "        \n",
    "        done = self.steps >= self.max_steps\n",
    "        \n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Precompute embeddings\n",
    "# ============================================================================\n",
    "\n",
    "def compute_embeddings(X):\n",
    "    \"\"\"Compute embeddings for all windows.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        tensors = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        embeds = ae_model.encode(tensors).cpu().numpy()\n",
    "    return embeds\n",
    "\n",
    "print(\"üîπ Precomputing embeddings for reconstructed data...\")\n",
    "embeddings_train = compute_embeddings(X_train_reconstructed)\n",
    "print(f\"‚úÖ Embeddings computed: {embeddings_train.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create VecEnv + QR-DQN\n",
    "# ============================================================================\n",
    "\n",
    "def make_env(rank):\n",
    "    def _init():\n",
    "        env = QRDQNAEEnvChronological(\n",
    "            X_train_reconstructed, \n",
    "            y_train_reconstructed, \n",
    "            supervision_mask,\n",
    "            ae_model,\n",
    "            embeddings_train,\n",
    "            lambda_int=0.8, \n",
    "            max_steps=200\n",
    "        )\n",
    "        return Monitor(env, f\"logs/env_{rank}\")\n",
    "    return _init\n",
    "\n",
    "num_envs = 1\n",
    "vec_env = DummyVecEnv([make_env(i) for i in range(num_envs)])\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "# Policy kwargs (deeper for distributional modeling)\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[512, 256]  # QR-DQN benefits from slightly deeper nets\n",
    ")\n",
    "\n",
    "model = QRDQN(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=150_000,         \n",
    "    learning_starts=5_000,\n",
    "    batch_size=64,\n",
    "    tau=1.0,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    target_update_interval=10_000,\n",
    "    exploration_fraction=0.2,\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.02,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    tensorboard_log=\"logs_qrdqn_ae_chronological/\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ Starting QR-DQN training with chronological data\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Train QR-DQN\n",
    "# ============================================================================\n",
    "\n",
    "model.learn(total_timesteps=200_000)  # More timesteps recommended for distributional methods\n",
    "model.save(\"qrdqn_ae_chronological\")\n",
    "vec_env.save(\"vec_normalize_qrdqn_chronological.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! Chronological QR-DQN model saved.\")\n",
    "print(\"   Model: qrdqn_ae_chronological.zip\")\n",
    "print(\"   VecNormalize: vec_normalize_qrdqn_chronological.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a59e7-068c-4097-b436-3ba134f64893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Load pretrained ConvAE (frozen) and AE stats\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ae_model = ConvAE(feat_dim=X_unlabeled.shape[2], seq_len=X_unlabeled.shape[1], latent_dim=128)\n",
    "ae_model.load_state_dict(torch.load(\"convAE_best.pth\", map_location=device))\n",
    "ae_model.to(device)\n",
    "ae_model.eval()\n",
    "for p in ae_model.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f\"‚úÖ Loaded ConvAE on {device} (frozen for DQN).\")\n",
    "\n",
    "stats = np.load(\"convAE_stats.npz\")\n",
    "ae_mean, ae_std = stats[\"mean_err\"], stats[\"std_err\"]\n",
    "print(f\"‚úÖ AE normalization loaded: mean={ae_mean:.6f}, std={ae_std:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Reconstruct chronological order\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ RECONSTRUCTING CHRONOLOGICAL ORDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load labeled and unlabeled data\n",
    "X_labeled = np.load(\"X_labeled.npy\")\n",
    "y_labeled = np.load(\"y_labeled.npy\")\n",
    "X_unlabeled = np.load(\"X_unlabeled.npy\")\n",
    "y_unlabeled = np.load(\"y_unlabeled.npy\")\n",
    "\n",
    "# Load indices\n",
    "labeled_indices = np.load(\"labeled_indices.npy\")\n",
    "unlabeled_indices = np.load(\"unlabeled_indices.npy\")\n",
    "train_split_size = np.load(\"train_split_size.npy\")[0]\n",
    "\n",
    "print(f\"üìä Data loaded:\")\n",
    "print(f\"   Labeled samples: {len(X_labeled):,}\")\n",
    "print(f\"   Unlabeled samples: {len(X_unlabeled):,}\")\n",
    "print(f\"   Original training size: {train_split_size:,}\")\n",
    "\n",
    "# Reconstruct X and y in chronological order\n",
    "X_train_reconstructed = np.zeros((train_split_size, *X_labeled.shape[1:]), dtype=X_labeled.dtype)\n",
    "y_train_reconstructed = np.zeros(train_split_size, dtype=y_labeled.dtype)\n",
    "\n",
    "# Place data back at original positions\n",
    "X_train_reconstructed[labeled_indices] = X_labeled\n",
    "y_train_reconstructed[labeled_indices] = y_labeled\n",
    "X_train_reconstructed[unlabeled_indices] = X_unlabeled\n",
    "y_train_reconstructed[unlabeled_indices] = y_unlabeled\n",
    "\n",
    "# Create supervision mask (1 = labeled/supervised, 0 = unlabeled/unsupervised)\n",
    "supervision_mask = np.zeros(train_split_size, dtype=np.int8)\n",
    "supervision_mask[labeled_indices] = 1\n",
    "\n",
    "print(f\"\\n‚úÖ Reconstructed training data:\")\n",
    "print(f\"   Shape: {X_train_reconstructed.shape}\")\n",
    "print(f\"   Supervised positions: {np.sum(supervision_mask):,} ({np.sum(supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "print(f\"   Unsupervised positions: {np.sum(1-supervision_mask):,} ({np.sum(1-supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "\n",
    "# Verify reconstruction\n",
    "y_train_original = np.load(\"y_train_seq.npy\")\n",
    "if np.array_equal(y_train_reconstructed, y_train_original):\n",
    "    print(\"‚úÖ VERIFICATION PASSED: Reconstruction matches original!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Reconstruction mismatch detected!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DQN Environment (Chronological Sequential)\n",
    "# ============================================================================\n",
    "\n",
    "class DQNAEEnvChronological(gym.Env):\n",
    "    \"\"\"\n",
    "    Sequential environment that processes windows in chronological order.\n",
    "    Uses supervision_mask to determine which positions have labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train, supervision_mask, ae_model,\n",
    "                 embeddings, lambda_int=1.0, max_steps=200):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.supervision_mask = supervision_mask\n",
    "        self.ae_model = ae_model\n",
    "        self.device = next(ae_model.parameters()).device\n",
    "        self.lambda_int = lambda_int\n",
    "        self.max_steps = max_steps\n",
    "        self.steps = 0\n",
    "        self.idx = 0\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        emb_dim = self.embeddings.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(emb_dim + 1,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = normal, 1 = anomaly\n",
    "\n",
    "        # Statistics\n",
    "        n_supervised = np.sum(supervision_mask)\n",
    "        n_unsupervised = len(supervision_mask) - n_supervised\n",
    "        print(f\"\\nüîπ Environment initialized:\")\n",
    "        print(f\"   Total windows: {len(X_train):,}\")\n",
    "        print(f\"   Supervised: {n_supervised:,} ({n_supervised/len(X_train)*100:.2f}%)\")\n",
    "        print(f\"   Unsupervised: {n_unsupervised:,} ({n_unsupervised/len(X_train)*100:.2f}%)\")\n",
    "\n",
    "    def _ae_error(self, x):\n",
    "        \"\"\"Compute normalized reconstruction error.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            recon = self.ae_model(x)\n",
    "            loss = F.mse_loss(recon, x, reduction=\"mean\").item()\n",
    "        norm = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "        return max(0, norm)\n",
    "\n",
    "    def reset(self, *, seed=45, options=None):\n",
    "        \"\"\"Reset to start of sequence (or random position 10% of time).\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        \n",
    "        # Start from beginning or random position\n",
    "        if np.random.rand() < 0.1:  # 10% random start for variety\n",
    "            self.idx = np.random.randint(0, len(self.X_train))\n",
    "        else:\n",
    "            self.idx = 0\n",
    "        \n",
    "        emb = self.embeddings[self.idx]\n",
    "        err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([emb, err]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take action on current window, move to next chronologically.\"\"\"\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Current window\n",
    "        x = self.X_train[self.idx]\n",
    "        true_label = self.y_train[self.idx]\n",
    "        is_supervised = self.supervision_mask[self.idx]\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        err = self._ae_error(x)\n",
    "        \n",
    "        # ========== REWARD CALCULATION ==========\n",
    "        \n",
    "        # External reward (only for supervised positions)\n",
    "        if is_supervised == 1:\n",
    "            # We have ground truth label\n",
    "            external_reward = 1.0 if action == true_label else -0.5\n",
    "        else:\n",
    "            # No supervision - no external reward\n",
    "            external_reward = 0.0\n",
    "        \n",
    "        # Intrinsic reward (based on reconstruction error)\n",
    "        # Encourage anomaly prediction when error is high\n",
    "        if action == 1:  # Predicted anomaly\n",
    "            intrinsic_reward = self.lambda_int * err\n",
    "            # Penalize weak false positives\n",
    "            if err < 0.05:\n",
    "                intrinsic_reward -= 0.5\n",
    "        else:  # Predicted normal\n",
    "            intrinsic_reward = 0.0\n",
    "        \n",
    "        # Total reward\n",
    "        reward = external_reward + intrinsic_reward\n",
    "        reward = np.clip(reward, -5, 5)\n",
    "        \n",
    "        # ========== MOVE TO NEXT WINDOW (CHRONOLOGICALLY) ==========\n",
    "        self.idx = (self.idx + 1) % len(self.X_train)\n",
    "        \n",
    "        # Next observation\n",
    "        next_emb = self.embeddings[self.idx]\n",
    "        next_err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([next_emb, next_err]).astype(np.float32)\n",
    "        \n",
    "        done = self.steps >= self.max_steps\n",
    "        \n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Precompute embeddings\n",
    "# ============================================================================\n",
    "\n",
    "def compute_embeddings(X):\n",
    "    \"\"\"Compute embeddings for all windows.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        tensors = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        embeds = ae_model.encode(tensors).cpu().numpy()\n",
    "    return embeds\n",
    "\n",
    "print(\"üîπ Precomputing embeddings for reconstructed data...\")\n",
    "embeddings_train = compute_embeddings(X_train_reconstructed)\n",
    "print(f\"‚úÖ Embeddings computed: {embeddings_train.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create VecEnv + DQN\n",
    "# ============================================================================\n",
    "\n",
    "def make_env(rank):\n",
    "    def _init():\n",
    "        env = DQNAEEnvChronological(\n",
    "            X_train_reconstructed, \n",
    "            y_train_reconstructed, \n",
    "            supervision_mask,\n",
    "            ae_model,\n",
    "            embeddings_train,\n",
    "            lambda_int=0.8, \n",
    "            max_steps=200\n",
    "        )\n",
    "        return Monitor(env, f\"logs/env_{rank}\")\n",
    "    return _init\n",
    "\n",
    "num_envs = 1\n",
    "vec_env = DummyVecEnv([make_env(i) for i in range(num_envs)])\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "# Simplified policy_kwargs for non-recurrent MLP (DQN Q-network)\n",
    "policy_kwargs = dict(\n",
    "    net_arch=[256, 256]  # Q-network layers\n",
    ")\n",
    "\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    vec_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=150_000,  # Replay buffer for off-policy learning\n",
    "    learning_starts=5_000,  # Warmup steps\n",
    "    batch_size=64,\n",
    "    tau=1.0,  # Target network update\n",
    "    gamma=0.99,\n",
    "    train_freq=4,  # Train every 4 steps\n",
    "    target_update_interval=1_000,\n",
    "    exploration_fraction=0.1,  # Epsilon decay\n",
    "    exploration_initial_eps=1.0,\n",
    "    exploration_final_eps=0.05,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    tensorboard_log=\"logs_dqn_ae_chronological/\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ Starting DQN training with chronological data\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Train DQN\n",
    "# ============================================================================\n",
    "\n",
    "model.learn(total_timesteps=500_000)\n",
    "model.save(\"dqn_ae_chronological\")\n",
    "vec_env.save(\"vec_normalize_dqn_chronological.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! Chronological DQN model saved.\")\n",
    "print(\"   Model: dqn_ae_chronological.zip\")\n",
    "print(\"   VecNormalize: vec_normalize_dqn_chronological.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b31f4-04e1-4521-8511-69910afdf73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# Load pretrained ConvAE (frozen) and AE stats\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ae_model = ConvAE(feat_dim=X_unlabeled.shape[2], seq_len=X_unlabeled.shape[1], latent_dim=128)\n",
    "ae_model.load_state_dict(torch.load(\"convAE_best.pth\", map_location=device))\n",
    "ae_model.to(device)\n",
    "ae_model.eval()\n",
    "for p in ae_model.parameters():\n",
    "    p.requires_grad = False\n",
    "print(f\"‚úÖ Loaded ConvAE on {device} (frozen for Standard PPO).\")\n",
    "\n",
    "stats = np.load(\"convAE_stats.npz\")\n",
    "ae_mean, ae_std = stats[\"mean_err\"], stats[\"std_err\"]\n",
    "print(f\"‚úÖ AE normalization loaded: mean={ae_mean:.6f}, std={ae_std:.6f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Reconstruct chronological order\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîÑ RECONSTRUCTING CHRONOLOGICAL ORDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load labeled and unlabeled data\n",
    "X_labeled = np.load(\"X_labeled.npy\")\n",
    "y_labeled = np.load(\"y_labeled.npy\")\n",
    "X_unlabeled = np.load(\"X_unlabeled.npy\")\n",
    "y_unlabeled = np.load(\"y_unlabeled.npy\")\n",
    "\n",
    "# Load indices\n",
    "labeled_indices = np.load(\"labeled_indices.npy\")\n",
    "unlabeled_indices = np.load(\"unlabeled_indices.npy\")\n",
    "train_split_size = np.load(\"train_split_size.npy\")[0]\n",
    "\n",
    "print(f\"üìä Data loaded:\")\n",
    "print(f\"   Labeled samples: {len(X_labeled):,}\")\n",
    "print(f\"   Unlabeled samples: {len(X_unlabeled):,}\")\n",
    "print(f\"   Original training size: {train_split_size:,}\")\n",
    "\n",
    "# Reconstruct X and y in chronological order\n",
    "X_train_reconstructed = np.zeros((train_split_size, *X_labeled.shape[1:]), dtype=X_labeled.dtype)\n",
    "y_train_reconstructed = np.zeros(train_split_size, dtype=y_labeled.dtype)\n",
    "\n",
    "# Place data back at original positions\n",
    "X_train_reconstructed[labeled_indices] = X_labeled\n",
    "y_train_reconstructed[labeled_indices] = y_labeled\n",
    "X_train_reconstructed[unlabeled_indices] = X_unlabeled\n",
    "y_train_reconstructed[unlabeled_indices] = y_unlabeled\n",
    "\n",
    "# Create supervision mask (1 = labeled/supervised, 0 = unlabeled/unsupervised)\n",
    "supervision_mask = np.zeros(train_split_size, dtype=np.int8)\n",
    "supervision_mask[labeled_indices] = 1\n",
    "\n",
    "print(f\"\\n‚úÖ Reconstructed training data:\")\n",
    "print(f\"   Shape: {X_train_reconstructed.shape}\")\n",
    "print(f\"   Supervised positions: {np.sum(supervision_mask):,} ({np.sum(supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "print(f\"   Unsupervised positions: {np.sum(1-supervision_mask):,} ({np.sum(1-supervision_mask)/train_split_size*100:.2f}%)\")\n",
    "\n",
    "# Verify reconstruction\n",
    "y_train_original = np.load(\"y_train_seq.npy\")\n",
    "if np.array_equal(y_train_reconstructed, y_train_original):\n",
    "    print(\"‚úÖ VERIFICATION PASSED: Reconstruction matches original!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Reconstruction mismatch detected!\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PPO Environment (Chronological Sequential)\n",
    "# ============================================================================\n",
    "\n",
    "class PPOAEEnvChronological(gym.Env):\n",
    "    \"\"\"\n",
    "    Sequential environment that processes windows in chronological order.\n",
    "    Uses supervision_mask to determine which positions have labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train, supervision_mask, ae_model,\n",
    "                 embeddings, lambda_int=1.0, max_steps=200):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.supervision_mask = supervision_mask\n",
    "        self.ae_model = ae_model\n",
    "        self.device = next(ae_model.parameters()).device\n",
    "        self.lambda_int = lambda_int\n",
    "        self.max_steps = max_steps\n",
    "        self.steps = 0\n",
    "        self.idx = 0\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        emb_dim = self.embeddings.shape[1]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(emb_dim + 1,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(2)  # 0 = normal, 1 = anomaly\n",
    "\n",
    "        # Statistics\n",
    "        n_supervised = np.sum(supervision_mask)\n",
    "        n_unsupervised = len(supervision_mask) - n_supervised\n",
    "        print(f\"\\nüîπ Environment initialized:\")\n",
    "        print(f\"   Total windows: {len(X_train):,}\")\n",
    "        print(f\"   Supervised: {n_supervised:,} ({n_supervised/len(X_train)*100:.2f}%)\")\n",
    "        print(f\"   Unsupervised: {n_unsupervised:,} ({n_unsupervised/len(X_train)*100:.2f}%)\")\n",
    "\n",
    "    def _ae_error(self, x):\n",
    "        \"\"\"Compute normalized reconstruction error.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "            recon = self.ae_model(x)\n",
    "            loss = F.mse_loss(recon, x, reduction=\"mean\").item()\n",
    "        norm = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "        return max(0, norm)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        \"\"\"Reset to start of sequence (or random position 10% of time).\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self.steps = 0\n",
    "        \n",
    "        # Start from beginning or random position\n",
    "        if np.random.rand() < 0.1:  # 10% random start for variety\n",
    "            self.idx = np.random.randint(0, len(self.X_train))\n",
    "        else:\n",
    "            self.idx = 0\n",
    "        \n",
    "        emb = self.embeddings[self.idx]\n",
    "        err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([emb, err]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take action on current window, move to next chronologically.\"\"\"\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Current window\n",
    "        x = self.X_train[self.idx]\n",
    "        true_label = self.y_train[self.idx]\n",
    "        is_supervised = self.supervision_mask[self.idx]\n",
    "        \n",
    "        # Compute reconstruction error\n",
    "        err = self._ae_error(x)\n",
    "        \n",
    "        # ========== REWARD CALCULATION ==========\n",
    "        \n",
    "        # External reward (only for supervised positions)\n",
    "        if is_supervised == 1:\n",
    "            # We have ground truth label\n",
    "            external_reward = 1.0 if action == true_label else -0.5\n",
    "        else:\n",
    "            # No supervision - no external reward\n",
    "            external_reward = 0.0\n",
    "        \n",
    "        # Intrinsic reward (based on reconstruction error)\n",
    "        # Encourage anomaly prediction when error is high\n",
    "        if action == 1:  # Predicted anomaly\n",
    "            intrinsic_reward = self.lambda_int * err\n",
    "            # Penalize weak false positives\n",
    "            if err < 0.05:\n",
    "                intrinsic_reward -= 0.5\n",
    "        else:  # Predicted normal\n",
    "            intrinsic_reward = 0.0\n",
    "        \n",
    "        # Total reward\n",
    "        reward = external_reward + intrinsic_reward\n",
    "        reward = np.clip(reward, -5, 5)\n",
    "        \n",
    "        # ========== MOVE TO NEXT WINDOW (CHRONOLOGICALLY) ==========\n",
    "        self.idx = (self.idx + 1) % len(self.X_train)\n",
    "        \n",
    "        # Next observation\n",
    "        next_emb = self.embeddings[self.idx]\n",
    "        next_err = np.array([self._ae_error(self.X_train[self.idx])])\n",
    "        obs = np.concatenate([next_emb, next_err]).astype(np.float32)\n",
    "        \n",
    "        done = self.steps >= self.max_steps\n",
    "        \n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Precompute embeddings\n",
    "# ============================================================================\n",
    "\n",
    "def compute_embeddings(X):\n",
    "    \"\"\"Compute embeddings for all windows.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        tensors = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "        embeds = ae_model.encode(tensors).cpu().numpy()\n",
    "    return embeds\n",
    "\n",
    "print(\"üîπ Precomputing embeddings for reconstructed data...\")\n",
    "embeddings_train = compute_embeddings(X_train_reconstructed)\n",
    "print(f\"‚úÖ Embeddings computed: {embeddings_train.shape}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create VecEnv + Standard PPO\n",
    "# ============================================================================\n",
    "\n",
    "def make_env(rank):\n",
    "    def _init():\n",
    "        env = PPOAEEnvChronological(\n",
    "            X_train_reconstructed, \n",
    "            y_train_reconstructed, \n",
    "            supervision_mask,\n",
    "            ae_model,\n",
    "            embeddings_train,\n",
    "            lambda_int=0.8, \n",
    "            max_steps=200\n",
    "        )\n",
    "        return Monitor(env, f\"logs/env_{rank}\")\n",
    "    return _init\n",
    "\n",
    "num_envs = 1\n",
    "vec_env = DummyVecEnv([make_env(i) for i in range(num_envs)])\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "# Standard MLP policy (no LSTM)\n",
    "policy_kwargs = dict(\n",
    "    net_arch=dict(pi=[256, 256], vf=[512, 512, 256])  # Same architecture as recurrent, but no LSTM\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",  # Standard MLP policy (non-recurrent)\n",
    "    vec_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    n_steps=64,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.02,\n",
    "    clip_range=0.2,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    tensorboard_log=\"logs_standard_ppo_ae_chronological/\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ Starting Standard PPO training with chronological data\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Train Standard PPO\n",
    "# ============================================================================\n",
    "\n",
    "model.learn(total_timesteps=500_000)\n",
    "model.save(\"standard_ppo_ae_chronological\")\n",
    "vec_env.save(\"vec_normalize_standard_ppo_chronological.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! Chronological Standard PPO model saved.\")\n",
    "print(\"   Model: standard_ppo_ae_chronological.zip\")\n",
    "print(\"   VecNormalize: vec_normalize_standard_ppo_chronological.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a34f6c-67b9-4605-a591-ccdc38342cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 20% unseen data\n",
    "\n",
    "#Recurrent PPO\n",
    "# Evaluation\n",
    "print(\"üìä Evaluating on test set...\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "from typing import NamedTuple, Tuple\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMStates(NamedTuple):\n",
    "    pi: Tuple[Tensor, Tensor]\n",
    "    vf: Tuple[Tensor, Tensor]\n",
    "\n",
    "\n",
    "# Your make_obs_array function (unchanged)\n",
    "def make_obs_array(X_windows):\n",
    "    obs_list = []\n",
    "    with torch.no_grad():\n",
    "        for x in X_windows:\n",
    "            t = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            emb = ae_model.encode(t).cpu().numpy().flatten()\n",
    "            recon = ae_model(t)\n",
    "            loss = F.mse_loss(recon, t, reduction=\"mean\").item()\n",
    "            err = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "            err = float(max(0.0, err))\n",
    "            obs = np.concatenate([emb, [err]]).astype(np.float32)\n",
    "            obs_list.append(obs)\n",
    "    return np.array(obs_list)\n",
    "\n",
    "obs_test = make_obs_array(X_test)\n",
    "\n",
    "# Inference loop\n",
    "y_pred = []\n",
    "y_probs = []\n",
    "lstm_states = None\n",
    "episode_start = True\n",
    "\n",
    "print(\"Running inference...\")\n",
    "for obs in obs_test:\n",
    "    obs_tensor = torch.tensor(obs.reshape(1, -1), dtype=torch.float32).to(device)\n",
    "    episode_start_tensor = torch.tensor([episode_start], dtype=torch.float32).to(device)\n",
    "\n",
    "    if lstm_states is None:\n",
    "        n_layers = model.policy.lstm_actor.num_layers\n",
    "        hidden_size = model.policy.lstm_actor.hidden_size\n",
    "        batch_size = 1\n",
    "        zeros = torch.zeros((n_layers, batch_size, hidden_size), device=device)\n",
    "        lstm_states = LSTMStates(pi=(zeros, zeros), vf=(zeros, zeros))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        distribution, new_lstm_states_pi = model.policy.get_distribution(\n",
    "            obs_tensor, lstm_states.pi, episode_start_tensor\n",
    "        )\n",
    "        latent_vf, new_lstm_states_vf = model.policy._process_sequence(\n",
    "            obs_tensor, lstm_states.vf, episode_start_tensor, model.policy.lstm_critic\n",
    "        )\n",
    "\n",
    "    lstm_states = LSTMStates(pi=new_lstm_states_pi, vf=new_lstm_states_vf)\n",
    "\n",
    "    act = distribution.mode()  # deterministic\n",
    "    prob_anomaly = distribution.distribution.probs[0, 1].item()\n",
    "\n",
    "    y_pred.append(int(act.item()))\n",
    "    y_probs.append(prob_anomaly)\n",
    "\n",
    "    episode_start = False\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_probs = np.array(y_probs)\n",
    "\n",
    "# === Metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)  # [[TN, FP], [FN, TP]]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# === Heatmap Confusion Matrix (Professional Style) ===\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True Normal (0)', 'True Anomaly (1)'],\n",
    "    columns=['Pred Normal (0)', 'Pred Anomaly (1)']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black',\n",
    "            cbar_kws={'label': 'Count'}, annot_kws={\"size\": 20, \"weight\": \"bold\"})\n",
    "plt.title('Confusion Matrix (Recurrent PPO)', fontsize=16, pad=20)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"\\nPrecision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")\n",
    "print(f\"AUC       : {auc:.4f}\")\n",
    "print(f\"TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "# === ROC Curve (Included as requested) ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=3, color='#2E86AB')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve (Recurrent PPO)', fontsize=16, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58984e-d522-4893-bb48-917a80ae9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Quantile Regression DQN (QR-DQN)\n",
    "print(\"üìä Evaluating QR-DQN...\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")  # binary: 0 = normal, 1 = anomaly\n",
    "\n",
    "\n",
    "# Reuse observation creation function (same as training)\n",
    "def make_obs_array(X_windows):\n",
    "    obs_list = []\n",
    "    with torch.no_grad():\n",
    "        for x in X_windows:\n",
    "            t = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            emb = ae_model.encode(t).cpu().numpy().flatten()\n",
    "            recon = ae_model(t)\n",
    "            loss = F.mse_loss(recon, t, reduction=\"mean\").item()\n",
    "            err = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "            err = float(max(0.0, err))\n",
    "            obs = np.concatenate([emb, [err]]).astype(np.float32)\n",
    "            obs_list.append(obs)\n",
    "    return np.array(obs_list)\n",
    "\n",
    "print(\"Preparing test observations...\")\n",
    "obs_test = make_obs_array(X_test)\n",
    "\n",
    "# === Inference for QR-DQN ===\n",
    "y_pred = []\n",
    "y_probs = []\n",
    "deterministic = True\n",
    "\n",
    "print(\"Running inference...\")\n",
    "for obs in obs_test:\n",
    "    obs_reshaped = obs.reshape(1, -1)\n",
    "\n",
    "    # Deterministic action (argmax over mean quantile)\n",
    "    action, _ = model.predict(obs_reshaped, deterministic=deterministic)\n",
    "    y_pred.append(int(action[0]))\n",
    "\n",
    "    # Get probability-like score for anomaly (action=1)\n",
    "    with torch.no_grad():\n",
    "        obs_tensor = torch.as_tensor(obs_reshaped, dtype=torch.float32).to(device)\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ Correct access for sb3-contrib QRDQN ‚îÄ‚îÄ‚îÄ\n",
    "        quantiles = model.policy.quantile_net(obs_tensor)   # [1, 200, 2]\n",
    "\n",
    "        # Average across quantiles ‚Üí approximate expected Q-value\n",
    "        q_mean = quantiles.mean(dim=1)                       # [1, 2]\n",
    "\n",
    "        probs = F.softmax(q_mean, dim=1)\n",
    "        prob_anomaly = probs[0, 1].item()                    # probability of anomaly (action 1)\n",
    "        y_probs.append(prob_anomaly)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_probs = np.array(y_probs)\n",
    "\n",
    "# === Metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)  # [[TN, FP], [FN, TP]]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# === Heatmap Confusion Matrix (Consistent Professional Style) ===\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True Normal (0)', 'True Anomaly (1)'],\n",
    "    columns=['Pred Normal (0)', 'Pred Anomaly (1)']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black',\n",
    "            cbar_kws={'label': 'Count'}, annot_kws={\"size\": 20, \"weight\": \"bold\"})\n",
    "plt.title('Confusion Matrix (QR-DQN)', fontsize=16, pad=20)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"\\nPrecision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")\n",
    "print(f\"AUC       : {auc:.4f}\")\n",
    "print(f\"TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "# === ROC Curve ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=3, color='#2E86AB')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve (QR-DQN)', fontsize=16, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ QR-DQN Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0593f8-d415-4c85-ba19-410288c278ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Non-Recurrent PPO\n",
    "print(\"üìä Evaluating PPO...\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")  # binary: 0 = normal, 1 = anomaly\n",
    "\n",
    "# Reuse make_obs_array function (same as training)\n",
    "def make_obs_array(X_windows):\n",
    "    obs_list = []\n",
    "    with torch.no_grad():\n",
    "        for x in X_windows:\n",
    "            t = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            emb = ae_model.encode(t).cpu().numpy().flatten()\n",
    "            recon = ae_model(t)\n",
    "            loss = F.mse_loss(recon, t, reduction=\"mean\").item()\n",
    "            err = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "            err = float(max(0.0, err))\n",
    "            obs = np.concatenate([emb, [err]]).astype(np.float32)\n",
    "            obs_list.append(obs)\n",
    "    return np.array(obs_list)\n",
    "\n",
    "print(\"Preparing test observations...\")\n",
    "obs_test = make_obs_array(X_test)\n",
    "\n",
    "# === Inference for PPO ===\n",
    "y_pred = []\n",
    "y_probs = []\n",
    "deterministic = True  # usually best for evaluation\n",
    "\n",
    "print(\"Running inference...\")\n",
    "for obs in obs_test:\n",
    "    obs_reshaped = obs.reshape(1, -1)\n",
    "\n",
    "    # Get deterministic action\n",
    "    action, _ = model.predict(obs_reshaped, deterministic=deterministic)\n",
    "    y_pred.append(int(action[0]))\n",
    "\n",
    "    # Get probability of anomaly (action = 1)\n",
    "    with torch.no_grad():\n",
    "        obs_tensor = torch.tensor(obs_reshaped, dtype=torch.float32).to(device)\n",
    "        distribution = model.policy.get_distribution(obs_tensor)\n",
    "        prob_anomaly = distribution.distribution.probs[0, 1].item()  # P(action=1)\n",
    "        y_probs.append(prob_anomaly)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_probs = np.array(y_probs)\n",
    "\n",
    "# === Metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)  # [[TN, FP], [FN, TP]]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall    = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1        = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc       = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# === Heatmap Confusion Matrix (Consistent Professional Style) ===\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True Normal (0)', 'True Anomaly (1)'],\n",
    "    columns=['Pred Normal (0)', 'Pred Anomaly (1)']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black',\n",
    "            cbar_kws={'label': 'Count'}, annot_kws={\"size\": 20, \"weight\": \"bold\"})\n",
    "plt.title('Confusion Matrix (PPO)', fontsize=16, pad=20)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"\\nPrecision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")\n",
    "print(f\"AUC       : {auc:.4f}\")\n",
    "print(f\"TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "# === ROC Curve ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=3, color='#2E86AB')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve (PPO)', fontsize=16, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ PPO Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df7dbf-144c-46be-92b0-82608a306eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for DQN\n",
    "print(\"üìä Evaluating DQN...\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")  # binary: 0 = normal, 1 = anomaly\n",
    "\n",
    "# Reuse make_obs_array function\n",
    "def make_obs_array(X_windows):\n",
    "    obs_list = []\n",
    "    with torch.no_grad():\n",
    "        for x in X_windows:\n",
    "            t = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            emb = ae_model.encode(t).cpu().numpy().flatten()\n",
    "            recon = ae_model(t)\n",
    "            loss = F.mse_loss(recon, t, reduction=\"mean\").item()\n",
    "            err = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "            err = float(max(0.0, err))\n",
    "            obs = np.concatenate([emb, [err]]).astype(np.float32)\n",
    "            obs_list.append(obs)\n",
    "    return np.array(obs_list)\n",
    "\n",
    "obs_test = make_obs_array(X_test)\n",
    "\n",
    "# === Inference for DQN ===\n",
    "y_pred = []\n",
    "y_probs = []\n",
    "deterministic = True\n",
    "\n",
    "print(\"Running inference...\")\n",
    "for obs in obs_test:\n",
    "    obs_reshaped = obs.reshape(1, -1)\n",
    "\n",
    "    # Deterministic action (argmax Q-value)\n",
    "    action, _ = model.predict(obs_reshaped, deterministic=deterministic)\n",
    "    y_pred.append(int(action[0]))\n",
    "\n",
    "    # Softmax over Q-values for probability of anomaly (action=1)\n",
    "    with torch.no_grad():\n",
    "        obs_tensor = torch.tensor(obs_reshaped, dtype=torch.float32).to(device)\n",
    "        q_values = model.q_net(obs_tensor)  # Shape: (1, 2)\n",
    "        probs = F.softmax(q_values, dim=1)\n",
    "        prob_anomaly = probs[0, 1].item()\n",
    "        y_probs.append(prob_anomaly)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_probs = np.array(y_probs)\n",
    "\n",
    "# === Metrics ===\n",
    "cm = confusion_matrix(y_test, y_pred)  # [[TN, FP], [FN, TP]]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# === Heatmap Confusion Matrix (Consistent Professional Style) ===\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True Normal (0)', 'True Anomaly (1)'],\n",
    "    columns=['Pred Normal (0)', 'Pred Anomaly (1)']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=1, linecolor='black',\n",
    "            cbar_kws={'label': 'Count'}, annot_kws={\"size\": 20, \"weight\": \"bold\"})\n",
    "plt.title('Confusion Matrix (DQN)', fontsize=16, pad=20)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"\\nPrecision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-Score  : {f1:.4f}\")\n",
    "print(f\"AUC       : {auc:.4f}\")\n",
    "print(f\"TP: {tp:,} | FP: {fp:,} | FN: {fn:,} | TN: {tn:,}\")\n",
    "\n",
    "# === ROC Curve ===\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})', linewidth=3, color='#2E86AB')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.7)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve (DQN)', fontsize=16, pad=20)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ DQN Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d53c15-73eb-4eb8-9a9d-78448bd62bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------\n",
    "print(\"üìÇ Loading dataset...\")\n",
    "df = pd.read_csv(\"EdgeIIoT-dataset.csv\")\n",
    "\n",
    "# Drop irrelevant identifier/payload columns\n",
    "drop_cols = [\n",
    "    \"ip.src_host\", \"ip.dst_host\", \"arp.dst.proto_ipv4\", \"arp.src.proto_ipv4\",\n",
    "    \"http.file_data\", \"http.request.uri.query\", \"http.referer\",\n",
    "    \"http.request.full_uri\", \"tcp.options\", \"tcp.payload\",\n",
    "    \"dns.qry.name\", \"dns.qry.name.len\", \"mqtt.msg\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Separate labels AND keep attack types\n",
    "# -----------------------------\n",
    "labels = df[[\"Attack_label\", \"Attack_type\"]].copy()\n",
    "attack_types_original = df[\"Attack_type\"].values  # *** NEW: Keep original attack types ***\n",
    "df = df.drop(columns=[\"Attack_label\", \"Attack_type\"], errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Encode categorical columns\n",
    "# -----------------------------\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.drop(\"frame.time\", errors=\"ignore\")\n",
    "for col in categorical_cols:\n",
    "    n_unique = df[col].nunique()\n",
    "    if n_unique < 50:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    else:\n",
    "        freq = df[col].value_counts()\n",
    "        df[col] = df[col].map(freq)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Scale numerical features\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "features = df.drop(columns=[\"frame.time\"], errors=\"ignore\")\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "X[\"Attack_label\"] = labels[\"Attack_label\"].values\n",
    "X[\"Attack_type\"] = labels[\"Attack_type\"].values\n",
    "if \"frame.time\" in df.columns:\n",
    "    X[\"frame.time\"] = df[\"frame.time\"].values\n",
    "\n",
    "# Sort chronologically (important for sequential structure)\n",
    "if \"frame.time\" in X.columns:\n",
    "    X = X.sort_values(\"frame.time\").reset_index(drop=True)\n",
    "    # *** IMPORTANT: Also reorder attack_types_original to match ***\n",
    "    attack_types_original = X[\"Attack_type\"].values\n",
    "\n",
    "print(f\"‚úÖ Preprocessed features: {X.shape[1]} columns\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Sliding window (stride = 4) WITH ATTACK TYPE TRACKING\n",
    "# -----------------------------\n",
    "def sliding_window_with_attack_types(data, binary_labels, attack_types, \n",
    "                                      window=32, step=4, anomaly_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Create sliding windows with robust anomaly labeling AND track attack types.\n",
    "    \n",
    "    Args:\n",
    "        data: Feature data\n",
    "        binary_labels: Binary labels (0=normal, 1=anomaly)\n",
    "        attack_types: Attack type strings for each packet\n",
    "        window: Window size (number of time steps)\n",
    "        step: Stride between windows\n",
    "        anomaly_threshold: Minimum proportion of anomalies needed (default: 0.4 = 40%)\n",
    "    \n",
    "    Returns:\n",
    "        X_seq: Array of windows (n_windows, window, n_features)\n",
    "        y_seq: Binary labels for windows (n_windows,)\n",
    "        attack_type_seq: Most prevalent attack type per window (n_windows,)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq, attack_type_seq = [], [], []\n",
    "    \n",
    "    for start in range(0, len(data) - window, step):\n",
    "        end = start + window\n",
    "        X_seq.append(data.iloc[start:end].values)\n",
    "        \n",
    "        # Calculate proportion of anomalies in this window\n",
    "        window_labels = binary_labels.iloc[start:end]\n",
    "        anomaly_ratio = window_labels.sum() / len(window_labels)\n",
    "        \n",
    "        # Label as anomalous only if >= threshold\n",
    "        y_seq.append(int(anomaly_ratio >= anomaly_threshold))\n",
    "        \n",
    "        # *** NEW: Determine most prevalent attack type in window ***\n",
    "        window_attack_types = attack_types[start:end]\n",
    "        most_common_attack = Counter(window_attack_types).most_common(1)[0][0]\n",
    "        attack_type_seq.append(most_common_attack)\n",
    "    \n",
    "    return (np.array(X_seq, dtype=np.float32), \n",
    "            np.array(y_seq, dtype=np.int8),\n",
    "            np.array(attack_type_seq))\n",
    "\n",
    "print(\"ü™ü Generating sliding windows (window=32, step=4, ‚â•40% anomalies required)...\")\n",
    "X_seq, y_seq, attack_type_seq = sliding_window_with_attack_types(\n",
    "    X.drop(columns=[\"Attack_label\", \"Attack_type\", \"frame.time\"], errors=\"ignore\"),\n",
    "    X[\"Attack_label\"],\n",
    "    attack_types_original,  # *** NEW: Pass attack types ***\n",
    "    window=32,\n",
    "    step=4,\n",
    "    anomaly_threshold=0.4  # 40% threshold\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Total windows: {len(X_seq):,}\")\n",
    "print(f\"‚úÖ Window shape: {X_seq.shape[1:]} (time steps √ó features)\")\n",
    "print(f\"‚úÖ Attack types tracked: {len(np.unique(attack_type_seq))} unique types\")\n",
    "\n",
    "# Show attack type distribution\n",
    "print(\"\\nüìä Attack type distribution in all windows:\")\n",
    "attack_counts = Counter(attack_type_seq)\n",
    "for attack_type, count in attack_counts.most_common(10):  # Top 10\n",
    "    pct = count / len(attack_type_seq) * 100\n",
    "    print(f\"  {attack_type:30s}: {count:8,} ({pct:5.2f}%)\")\n",
    "if len(attack_counts) > 10:\n",
    "    print(f\"  ... and {len(attack_counts) - 10} more attack types\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Chronological Train/Test Split (80/20, time-based)\n",
    "# -----------------------------\n",
    "split_idx = int(0.8 * len(X_seq))  # First 80% train, last 20% test\n",
    "X_train_seq = X_seq[:split_idx]\n",
    "y_train_seq = y_seq[:split_idx]\n",
    "attack_types_train = attack_type_seq[:split_idx]  # *** NEW: Split attack types ***\n",
    "\n",
    "X_test = X_seq[split_idx:]\n",
    "y_test = y_seq[split_idx:]\n",
    "attack_types_test = attack_type_seq[split_idx:]  # *** NEW: Split attack types ***\n",
    "\n",
    "# From train: Create ConvAE + PPO sets\n",
    "anomaly_indices = np.where(y_train_seq == 1)[0]\n",
    "num_labeled = int(0.05 * len(anomaly_indices))  # 5% labeled anomalies\n",
    "\n",
    "labeled_anom_idx = np.random.choice(anomaly_indices, num_labeled, replace=False)\n",
    "X_labeled = X_train_seq[labeled_anom_idx]\n",
    "y_labeled = y_train_seq[labeled_anom_idx]\n",
    "\n",
    "unlabeled_idx = np.setdiff1d(np.arange(len(X_train_seq)), labeled_anom_idx)\n",
    "X_unlabeled = X_train_seq[unlabeled_idx]\n",
    "y_unlabeled = y_train_seq[unlabeled_idx]  # For sanity checks only; hide in training\n",
    "\n",
    "# ConvAE trained only on normal sequences from train\n",
    "normal_indices = np.where(y_train_seq == 0)[0]\n",
    "X_ae = X_train_seq[normal_indices]\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save outputs WITH INDICES AND ATTACK TYPES\n",
    "# -----------------------------\n",
    "np.save(\"X_ae.npy\", X_ae)\n",
    "np.save(\"X_unlabeled.npy\", X_unlabeled)\n",
    "np.save(\"y_unlabeled.npy\", y_unlabeled)\n",
    "np.save(\"X_labeled.npy\", X_labeled)\n",
    "np.save(\"y_labeled.npy\", y_labeled)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "np.save(\"y_train_seq.npy\", y_train_seq)\n",
    "\n",
    "# *** NEW: Save attack types ***\n",
    "np.save(\"attack_types_test.npy\", attack_types_test)\n",
    "np.save(\"attack_types_train.npy\", attack_types_train)\n",
    "\n",
    "# Save indices for reconstruction\n",
    "np.save(\"labeled_indices.npy\", labeled_anom_idx)\n",
    "np.save(\"unlabeled_indices.npy\", unlabeled_idx)\n",
    "np.save(\"train_split_size.npy\", np.array([len(X_train_seq)]))\n",
    "\n",
    "print(\"\\nüíæ Saved arrays:\")\n",
    "print(f\"  X_ae         : {X_ae.shape} ({X_ae.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_unlabeled  : {X_unlabeled.shape} ({X_unlabeled.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_labeled    : {X_labeled.shape} ({X_labeled.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"  X_test       : {X_test.shape} ({X_test.nbytes / 1e9:.2f} GB)\")\n",
    "print(f\"\\n  attack_types_test  : {attack_types_test.shape}\")\n",
    "print(f\"  attack_types_train : {attack_types_train.shape}\")\n",
    "print(f\"  labeled_indices    : {labeled_anom_idx.shape}\")\n",
    "print(f\"  unlabeled_indices  : {unlabeled_idx.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Dataset Statistics\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training split statistics\n",
    "train_normal = np.sum(y_train_seq == 0)\n",
    "train_anomaly = np.sum(y_train_seq == 1)\n",
    "train_total = len(y_train_seq)\n",
    "print(f\"\\nüîπ TRAINING SPLIT (First 80% chronologically):\")\n",
    "print(f\"  Total windows    : {train_total:,}\")\n",
    "print(f\"  Normal windows   : {train_normal:,} ({train_normal/train_total*100:.2f}%)\")\n",
    "print(f\"  Anomaly windows  : {train_anomaly:,} ({train_anomaly/train_total*100:.2f}%)\")\n",
    "\n",
    "# Test split statistics\n",
    "test_normal = np.sum(y_test == 0)\n",
    "test_anomaly = np.sum(y_test == 1)\n",
    "test_total = len(y_test)\n",
    "print(f\"\\nüîπ TEST SPLIT (Last 20% chronologically):\")\n",
    "print(f\"  Total windows    : {test_total:,}\")\n",
    "print(f\"  Normal windows   : {test_normal:,} ({test_normal/test_total*100:.2f}%)\")\n",
    "print(f\"  Anomaly windows  : {test_anomaly:,} ({test_anomaly/test_total*100:.2f}%)\")\n",
    "\n",
    "# *** NEW: Attack type statistics for test set ***\n",
    "print(f\"\\nüîπ TEST SET ATTACK TYPES:\")\n",
    "test_attack_counts = Counter(attack_types_test)\n",
    "for attack_type, count in test_attack_counts.most_common():\n",
    "    pct = count / len(attack_types_test) * 100\n",
    "    print(f\"  {attack_type:30s}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nüîπ OVERALL:\")\n",
    "print(f\"  Total windows    : {train_total + test_total:,}\")\n",
    "print(f\"  Normal windows   : {train_normal + test_normal:,}\")\n",
    "print(f\"  Anomaly windows  : {train_anomaly + test_anomaly:,}\")\n",
    "print(f\"  Unique attacks   : {len(np.unique(attack_type_seq))}\")\n",
    "\n",
    "# Labeled data info\n",
    "print(f\"\\nüîπ LABELED ANOMALIES (for PPO training):\")\n",
    "print(f\"  Labeled anomalies: {len(X_labeled):,} ({len(X_labeled)/train_anomaly*100:.2f}% of train anomalies)\")\n",
    "print(f\"  Unlabeled data   : {len(X_unlabeled):,}\")\n",
    "print(f\"  ConvAE data      : {len(X_ae):,} (normal sequences only)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ Preprocessing complete! Ready for ConvAE and PPO training.\")\n",
    "print(f\"‚úÖ Index files saved for reconstruction: labeled_indices.npy, unlabeled_indices.npy\")\n",
    "print(f\"‚úÖ Attack type information saved: attack_types_test.npy, attack_types_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d852e-3c27-4e7e-a69c-44b843ff7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-Model Comparison Across Attack Types\n",
    "Evaluates DQN, QR-DQN, PPO, and Recurrent PPO on each attack type\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import NamedTuple, Tuple\n",
    "from torch import Tensor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üî¨ MULTI-MODEL ATTACK-TYPE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load test data and attack types\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìÇ Loading test data...\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "attack_types_test = np.load(\"attack_types_test.npy\")\n",
    "\n",
    "print(f\"‚úÖ Test samples: {len(y_test):,}\")\n",
    "print(f\"‚úÖ Attack types: {len(np.unique(attack_types_test))}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Define helper functions\n",
    "# ============================================================================\n",
    "\n",
    "class LSTMStates(NamedTuple):\n",
    "    pi: Tuple[Tensor, Tensor]\n",
    "    vf: Tuple[Tensor, Tensor]\n",
    "\n",
    "\n",
    "def make_obs_array(X_windows, ae_model, ae_mean, ae_std, device):\n",
    "    \"\"\"Create observations from windows (shared across all models)\"\"\"\n",
    "    obs_list = []\n",
    "    with torch.no_grad():\n",
    "        for x in X_windows:\n",
    "            t = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            emb = ae_model.encode(t).cpu().numpy().flatten()\n",
    "            recon = ae_model(t)\n",
    "            loss = F.mse_loss(recon, t, reduction=\"mean\").item()\n",
    "            err = np.tanh((loss - ae_mean) / (ae_std + 1e-8))\n",
    "            err = float(max(0.0, err))\n",
    "            obs = np.concatenate([emb, [err]]).astype(np.float32)\n",
    "            obs_list.append(obs)\n",
    "    return np.array(obs_list)\n",
    "\n",
    "\n",
    "def evaluate_recurrent_ppo(model, obs_test, device):\n",
    "    \"\"\"Evaluate Recurrent PPO model\"\"\"\n",
    "    print(\"  üîÑ Evaluating Recurrent PPO...\")\n",
    "    y_pred = []\n",
    "    lstm_states = None\n",
    "    episode_start = True\n",
    "    \n",
    "    for obs in obs_test:\n",
    "        obs_tensor = torch.tensor(obs.reshape(1, -1), dtype=torch.float32).to(device)\n",
    "        episode_start_tensor = torch.tensor([episode_start], dtype=torch.float32).to(device)\n",
    "        \n",
    "        if lstm_states is None:\n",
    "            n_layers = model.policy.lstm_actor.num_layers\n",
    "            hidden_size = model.policy.lstm_actor.hidden_size\n",
    "            batch_size = 1\n",
    "            zeros = torch.zeros((n_layers, batch_size, hidden_size), device=device)\n",
    "            lstm_states = LSTMStates(pi=(zeros, zeros), vf=(zeros, zeros))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            distribution, new_lstm_states_pi = model.policy.get_distribution(\n",
    "                obs_tensor, lstm_states.pi, episode_start_tensor\n",
    "            )\n",
    "            latent_vf, new_lstm_states_vf = model.policy._process_sequence(\n",
    "                obs_tensor, lstm_states.vf, episode_start_tensor, model.policy.lstm_critic\n",
    "            )\n",
    "        \n",
    "        lstm_states = LSTMStates(pi=new_lstm_states_pi, vf=new_lstm_states_vf)\n",
    "        act = distribution.mode()\n",
    "        y_pred.append(int(act.item()))\n",
    "        episode_start = False\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def evaluate_standard_ppo(model, obs_test, device):\n",
    "    \"\"\"Evaluate Standard PPO model\"\"\"\n",
    "    print(\"  üîÑ Evaluating Standard PPO...\")\n",
    "    y_pred = []\n",
    "    \n",
    "    for obs in obs_test:\n",
    "        obs_tensor = torch.tensor(obs.reshape(1, -1), dtype=torch.float32).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action, _ = model.predict(obs_tensor.cpu().numpy(), deterministic=True)\n",
    "        \n",
    "        y_pred.append(int(action[0]))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def evaluate_dqn(model, obs_test, device):\n",
    "    \"\"\"Evaluate DQN model\"\"\"\n",
    "    print(\"  üîÑ Evaluating DQN...\")\n",
    "    y_pred = []\n",
    "    \n",
    "    for obs in obs_test:\n",
    "        obs_reshaped = obs.reshape(1, -1)\n",
    "        action, _ = model.predict(obs_reshaped, deterministic=True)\n",
    "        y_pred.append(int(action[0]))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "def evaluate_qrdqn(model, obs_test, device):\n",
    "    \"\"\"Evaluate QR-DQN model\"\"\"\n",
    "    print(\"  üîÑ Evaluating QR-DQN...\")\n",
    "    y_pred = []\n",
    "    \n",
    "    for obs in obs_test:\n",
    "        obs_reshaped = obs.reshape(1, -1)\n",
    "        action, _ = model.predict(obs_reshaped, deterministic=True)\n",
    "        y_pred.append(int(action[0]))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Load all models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì¶ Loading models and preprocessing components...\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load ConvAE (shared by all models)\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from sb3_contrib import QRDQN, RecurrentPPO\n",
    "\n",
    "print(\"  Loading ConvAE...\")\n",
    "ae_model = ConvAE(feat_dim=X_test.shape[2], seq_len=X_test.shape[1], latent_dim=128)\n",
    "ae_model.load_state_dict(torch.load(\"convAE_best.pth\", map_location=device))\n",
    "ae_model.to(device)\n",
    "ae_model.eval()\n",
    "\n",
    "stats = np.load(\"convAE_stats.npz\")\n",
    "ae_mean, ae_std = stats[\"mean_err\"], stats[\"std_err\"]\n",
    "\n",
    "# Prepare observations (shared)\n",
    "print(\"  Creating observations...\")\n",
    "obs_test = make_obs_array(X_test, ae_model, ae_mean, ae_std, device)\n",
    "\n",
    "# Load all trained models\n",
    "models = {}\n",
    "\n",
    "try:\n",
    "    print(\"  Loading DQN...\")\n",
    "    models['DQN'] = DQN.load(\"dqn_ae_chronological.zip\", device=device)\n",
    "except:\n",
    "    print(\"    ‚ö†Ô∏è  DQN model not found\")\n",
    "\n",
    "try:\n",
    "    print(\"  Loading QR-DQN...\")\n",
    "    models['QR-DQN'] = QRDQN.load(\"qrdqn_ae_chronological.zip\", device=device)\n",
    "except:\n",
    "    print(\"    ‚ö†Ô∏è  QR-DQN model not found\")\n",
    "\n",
    "try:\n",
    "    print(\"  Loading PPO...\")\n",
    "    models['PPO'] = PPO.load(\"standard_ppo_ae_chronological.zip\", device=device)\n",
    "except:\n",
    "    print(\"    ‚ö†Ô∏è  PPO model not found\")\n",
    "\n",
    "try:\n",
    "    print(\"  Loading Recurrent PPO...\")\n",
    "    models['Recurrent PPO'] = RecurrentPPO.load(\"recurrent_ppo_ae_chronological.zip\", device=device)\n",
    "except:\n",
    "    print(\"    ‚ö†Ô∏è  Recurrent PPO model not found\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(models)} models: {list(models.keys())}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Evaluate all models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üß™ RUNNING EVALUATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    if model_name == \"Recurrent PPO\":\n",
    "        predictions[model_name] = evaluate_recurrent_ppo(model, obs_test, device)\n",
    "    elif model_name == \"PPO\":\n",
    "        predictions[model_name] = evaluate_standard_ppo(model, obs_test, device)\n",
    "    elif model_name == \"DQN\":\n",
    "        predictions[model_name] = evaluate_dqn(model, obs_test, device)\n",
    "    elif model_name == \"QR-DQN\":\n",
    "        predictions[model_name] = evaluate_qrdqn(model, obs_test, device)\n",
    "    \n",
    "    print(f\"    ‚úÖ Predictions: {len(predictions[model_name]):,}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Calculate per-attack metrics for all models\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CALCULATING PER-ATTACK METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get unique attack types\n",
    "unique_attacks = sorted(np.unique(attack_types_test))\n",
    "print(f\"\\nFound {len(unique_attacks)} attack types:\")\n",
    "for attack in unique_attacks:\n",
    "    count = (attack_types_test == attack).sum()\n",
    "    pct = count / len(attack_types_test) * 100\n",
    "    print(f\"  ‚Ä¢ {attack:30s}: {count:6,} ({pct:5.2f}%)\")\n",
    "\n",
    "# Build comprehensive results table\n",
    "results_data = []\n",
    "\n",
    "for attack_type in unique_attacks:\n",
    "    # Filter data for this attack type\n",
    "    mask = attack_types_test == attack_type\n",
    "    y_true_attack = y_test[mask]\n",
    "    n_samples = len(y_true_attack)\n",
    "    pct_total = n_samples / len(y_test) * 100\n",
    "    \n",
    "    # Calculate metrics for each model\n",
    "    for model_name, y_pred_all in predictions.items():\n",
    "        y_pred_attack = y_pred_all[mask]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = precision_score(y_true_attack, y_pred_attack, zero_division=0)\n",
    "        recall = recall_score(y_true_attack, y_pred_attack, zero_division=0)\n",
    "        f1 = f1_score(y_true_attack, y_pred_attack, zero_division=0)\n",
    "        \n",
    "        results_data.append({\n",
    "            'AttackType': attack_type,\n",
    "            'Count': n_samples,\n",
    "            '% of Total': pct_total,\n",
    "            'Model': model_name,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Format and display table (EXACTLY like your image)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã RESULTS TABLE (Formatted)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Pivot table to match your image format\n",
    "# Group by attack type and display all models for each attack\n",
    "for attack_type in unique_attacks:\n",
    "    attack_data = results_df[results_df['AttackType'] == attack_type]\n",
    "    \n",
    "    if len(attack_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get count and percentage (same for all models)\n",
    "    count = attack_data.iloc[0]['Count']\n",
    "    pct = attack_data.iloc[0]['% of Total']\n",
    "    \n",
    "    # Print attack type header\n",
    "    print(f\"{attack_type:<20} {count:>10,} {pct:>10.2f}%\")\n",
    "    \n",
    "    # Print each model's metrics\n",
    "    for _, row in attack_data.iterrows():\n",
    "        print(f\"{'':20} {'':10} {'':10}   \"\n",
    "              f\"{row['Model']:<15} \"\n",
    "              f\"{row['Precision']:>10.4f} \"\n",
    "              f\"{row['Recall']:>10.4f} \"\n",
    "              f\"{row['F1-Score']:>10.4f}\")\n",
    "    \n",
    "    print()  # Blank line between attack types\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Save to CSV and Excel (for easy copy-paste)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üíæ SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save detailed results\n",
    "results_df.to_csv('all_models_per_attack_comparison.csv', index=False)\n",
    "print(\"‚úÖ Saved: all_models_per_attack_comparison.csv\")\n",
    "\n",
    "# Create pivot table for easier viewing\n",
    "pivot_df = results_df.pivot_table(\n",
    "    index=['AttackType', 'Count', '% of Total'],\n",
    "    columns='Model',\n",
    "    values=['Precision', 'Recall', 'F1-Score']\n",
    ")\n",
    "pivot_df.to_csv('all_models_pivot_table.csv')\n",
    "print(\"‚úÖ Saved: all_models_pivot_table.csv\")\n",
    "\n",
    "# Create formatted table exactly like your image\n",
    "formatted_rows = []\n",
    "for attack_type in unique_attacks:\n",
    "    attack_data = results_df[results_df['AttackType'] == attack_type]\n",
    "    \n",
    "    if len(attack_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    count = int(attack_data.iloc[0]['Count'])\n",
    "    pct = attack_data.iloc[0]['% of Total']\n",
    "    \n",
    "    for idx, row in attack_data.iterrows():\n",
    "        formatted_rows.append({\n",
    "            'AttackType': attack_type if idx == attack_data.index[0] else '',\n",
    "            'Count': count if idx == attack_data.index[0] else '',\n",
    "            '% of Total': f\"{pct:.2f}%\" if idx == attack_data.index[0] else '',\n",
    "            'Model': row['Model'],\n",
    "            'Precision': f\"{row['Precision']:.4f}\",\n",
    "            'Recall': f\"{row['Recall']:.4f}\",\n",
    "            'F1-Score': f\"{row['F1-Score']:.4f}\"\n",
    "        })\n",
    "\n",
    "formatted_df = pd.DataFrame(formatted_rows)\n",
    "formatted_df.to_csv('formatted_comparison_table.csv', index=False)\n",
    "print(\"‚úÖ Saved: formatted_comparison_table.csv (ready for copy-paste!)\")\n",
    "\n",
    "# Also save as Excel for better formatting\n",
    "try:\n",
    "    formatted_df.to_excel('formatted_comparison_table.xlsx', index=False)\n",
    "    print(\"‚úÖ Saved: formatted_comparison_table.xlsx\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Excel save failed (install openpyxl: pip install openpyxl)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Visualization - Heatmap comparison\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create F1-Score heatmap\n",
    "pivot_f1 = results_df.pivot_table(\n",
    "    index='AttackType',\n",
    "    columns='Model',\n",
    "    values='F1-Score'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, max(8, len(unique_attacks) * 0.5)))\n",
    "sns.heatmap(pivot_f1, annot=True, fmt='.4f', cmap='RdYlGn', \n",
    "            vmin=0, vmax=1, linewidths=0.5, cbar_kws={'label': 'F1-Score'})\n",
    "plt.title('F1-Score Comparison Across Models and Attack Types', fontsize=14, pad=15)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Attack Type', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('f1_score_heatmap_all_models.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: f1_score_heatmap_all_models.png\")\n",
    "plt.show()\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    pivot_metric = results_df.pivot_table(\n",
    "        index='AttackType',\n",
    "        columns='Model',\n",
    "        values=metric\n",
    "    )\n",
    "    \n",
    "    pivot_metric.plot(kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_title(f'{metric} by Attack Type', fontsize=13, pad=10)\n",
    "    ax.set_xlabel('Attack Type', fontsize=11)\n",
    "    ax.set_ylabel(metric, fontsize=11)\n",
    "    ax.legend(title='Model', fontsize=9)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_comparison_all_models.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: metrics_comparison_all_models.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Summary statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in predictions.keys():\n",
    "    model_data = results_df[results_df['Model'] == model_name]\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Mean F1-Score: {model_data['F1-Score'].mean():.4f} (¬±{model_data['F1-Score'].std():.4f})\")\n",
    "    print(f\"  Best Attack:   {model_data.loc[model_data['F1-Score'].idxmax(), 'AttackType']} \"\n",
    "          f\"(F1={model_data['F1-Score'].max():.4f})\")\n",
    "    print(f\"  Worst Attack:  {model_data.loc[model_data['F1-Score'].idxmin(), 'AttackType']} \"\n",
    "          f\"(F1={model_data['F1-Score'].min():.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ COMPARISON COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  üìÑ all_models_per_attack_comparison.csv\")\n",
    "print(\"  üìÑ formatted_comparison_table.csv (‚Üê USE THIS for tables!)\")\n",
    "print(\"  üìÑ formatted_comparison_table.xlsx\")\n",
    "print(\"  üìä f1_score_heatmap_all_models.png\")\n",
    "print(\"  üìä metrics_comparison_all_models.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
